{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "from datetime import datetime\n",
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TF\n",
    "from io import BytesIO\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import random, torch, os, numpy as np\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import sys\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torchvision.utils import save_image\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torchvision.transforms as T\n",
    "import torchvision\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, down=True, use_act=True, **kwargs):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, padding_mode=\"reflect\", **kwargs)\n",
    "            if down\n",
    "            else nn.ConvTranspose2d(in_channels, out_channels, **kwargs),\n",
    "            nn.InstanceNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True) if use_act else nn.Identity()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            ConvBlock(channels, channels, kernel_size=3, padding=1),\n",
    "            ConvBlock(channels, channels, use_act=False, kernel_size=3, padding=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, img_channels, num_features = 64, num_residuals=9):\n",
    "        super().__init__()\n",
    "        self.initial = nn.Sequential(\n",
    "            nn.Conv2d(img_channels, num_features, kernel_size=7, stride=1, padding=3, padding_mode=\"reflect\"),\n",
    "            nn.InstanceNorm2d(num_features),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.down_blocks = nn.ModuleList(\n",
    "            [\n",
    "                ConvBlock(num_features, num_features*2, kernel_size=3, stride=2, padding=1),\n",
    "                ConvBlock(num_features*2, num_features*4, kernel_size=3, stride=2, padding=1),\n",
    "            ]\n",
    "        )\n",
    "        self.res_blocks = nn.Sequential(\n",
    "            *[ResidualBlock(num_features*4) for _ in range(num_residuals)]\n",
    "        )\n",
    "        self.up_blocks = nn.ModuleList(\n",
    "            [\n",
    "                ConvBlock(num_features*4, num_features*2, down=False, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "                ConvBlock(num_features*2, num_features*1, down=False, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.last = nn.Conv2d(num_features*1, img_channels, kernel_size=7, stride=1, padding=3, padding_mode=\"reflect\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.initial(x)\n",
    "        for layer in self.down_blocks:\n",
    "            x = layer(x)\n",
    "        x = self.res_blocks(x)\n",
    "        for layer in self.up_blocks:\n",
    "            x = layer(x)\n",
    "        return torch.tanh(self.last(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "'''\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import transforms\n",
    "from PIL import Image\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = [f for f in os.listdir(root_dir) if os.path.isfile(os.path.join(root_dir, f)) and f.endswith('.bmp')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.root_dir, self.image_files[idx])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image\n",
    "\n",
    "# Define the transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((576, 640)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Directory to save the generated images\n",
    "SAVE_DIR = \"generated_images\"\n",
    "if not os.path.exists(SAVE_DIR):\n",
    "    os.makedirs(SAVE_DIR)\n",
    "\n",
    "# Initialize the dataset and dataloader\n",
    "dataset = CustomImageDataset(root_dir='data/train/good/good_200/', transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# Define a function to denormalize the tensor images\n",
    "def denormalize(tensor):\n",
    "    tensor = tensor * 0.5 + 0.5\n",
    "    return tensor.clamp(0, 1)\n",
    "\n",
    "MODEL_DIRS = [\n",
    "   \n",
    "]\n",
    "\n",
    "for model_dir in MODEL_DIRS:\n",
    "    model_path = os.path.join(\"results\",model_dir,\"saved_images\", 'genm.pth.tar')\n",
    "    gen_M = Generator(img_channels=3, num_residuals=9).to(DEVICE)\n",
    "    checkpoint = torch.load(model_path, map_location=DEVICE)\n",
    "    gen_M.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    model = gen_M.to(DEVICE)\n",
    "\n",
    "    # Load the model\n",
    "    # model_path = os.path.join(model_dir, 'genm.pth.tar')\n",
    "    # model =  Generator(img_channels=3, num_residuals=9).to(DEVICE)\n",
    "    # model.load_state_dict(torch.load(model_dir, map_location=DEVICE))  # Load the state dict\n",
    "    # model = model.to(DEVICE)  # Send model to device\n",
    "    # model.eval()  # Set to evaluation mode\n",
    "\n",
    "    # Create a directory to save generated images for this model\n",
    "    save_dir = os.path.join('generated', model_dir)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # Generate and save the images\n",
    "    for i, input_images in enumerate(dataloader):\n",
    "        input_images = input_images.to(DEVICE)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            generated_images = model(input_images)  # Generate images\n",
    "            generated_images = denormalize(generated_images)  # Denormalize\n",
    "\n",
    "        # Save the generated images\n",
    "        \n",
    "        save_path = os.path.join(save_dir, f'image_{i:04d}.png')\n",
    "        print(save_path)\n",
    "        save_image(generated_images, save_path)\n",
    "\n",
    "    print(f\"Images from {model_dir} have been generated and saved.\")\n",
    "\n",
    "print(\"All images have been generated and saved.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
